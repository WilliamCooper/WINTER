%% LyX 2.1.2 created this file.  For more info, see http://www.lyx.org/.
\documentclass[12pt]{article}
\usepackage{mathptmx}
\usepackage[T1]{fontenc}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=3.54cm,bmargin=2.54cm,lmargin=2.54cm,rmargin=2.54cm,headheight=1cm,headsep=2cm,footskip=0.5cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}
\usepackage{color}
\usepackage[unicode=true,colorlinks=true,linkcolor=black,urlcolor=blue]
{hyperref}
\usepackage{breakurl}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\input colordvi
\usepackage{color}
\fancyhead{}
\fancyfoot[CE,CO]{}
\newtoks{\addressee} \global\addressee={}
\newdimen\longindent \longindent=3.5truein
\fancyhead[L]{Memo to: \the\addressee \\ \datetoday \\ Page \thepage \hfill}
\renewcommand{\headrulewidth}{0.0pt}
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
\setlength{\leftmargin}{\labelwidth}
\addtolength{\leftmargin}{\labelsep}
\renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}
\newcommand{\datetoday}{\number\day\space
     \ifcase\month\or January\or February\or March\or April\or May\or
     June\or July\or August\or September\or October\or November\or
     December\fi
     \space\number\year}
\newcommand{\EOLmemo}{\null \vskip-1.5truein
{\raggedright \textsf{\textsc{\large \textcolor{blue}{Earth Observing Laboratory}}}}\par
{\raggedright \textsf{\textsl{\textcolor{blue}{Memorandum:}}}} \par \vskip6pt
{\color{blue}{\hrule}}\par
\vskip0.3truein \leftline{\hskip \longindent \datetoday} \vskip0.2truein
\thispagestyle{empty}}
\newcommand{\attachm}[1]{\begin{lyxlist}{Attachments:00}
\item [Attachments:] {#1}
\end{lyxlist}}
\newcommand{\cc}[1]{\begin{lyxlist}{Attachments:00}
\item [cc:] {#1}
\end{lyxlist}}
\newcommand{\attach}[1]{\begin{lyxlist}{Attachments:00}
\item [Attachment:] {#1}
\end{lyxlist}}
%usage: \encl{A\\B\\C} or \cc{ma,e1\\name2\\name3}

\makeatother

\begin{document}
\EOLmemo 

\global\addressee={WINTER data-processing file}  % >>change "File" to the "To:" name desired

\begin{tabular}{ll}
\textsf{\textsc{\textcolor{blue}{To:}}} & \the\addressee\tabularnewline
\textsf{\textsc{\textcolor{blue}{From:}}} & Al Cooper\tabularnewline
\textsf{\textsc{\textcolor{blue}{Subject:}}} & Data review: Using the 'Review.R' program\tabularnewline
\end{tabular}

\bigskip


\section{General description}

This program uses a set of functions to make plots that are designed
to provide a starting point for quality assessment for C-130 projects,
starting with WINTER. This structure makes it easy to change the set of plots
for a particular project, to refine the time range for plots, to re-generate
a subset of the plots, to add new plots, and otherwise to tailor the
output to project and personal needs. This memo shows typical output
from the program, suggests how each plot should look and how to spot
problems, and provides a record of how output should look when systems
are functioning properly

By default the script uses a standard set of plots, encoded in the
program where nplots is defined, but a
user can change that set interactively or with run-time
arguments. The script normally produces a PDF file and an HTML file
that are concatenations of the plots produced. PNG files are also
produced and reside in the subdirectory Figures, but these are overwritten
with each run so should be saved between runs if it is desirable to
preserve them. The PDF file
has the advantage of maintaining quality when magnified 
but the HTML files are much smaller and suitable for display in
a browser, so both are produced in a normal run.

Other ways to use the Review.R script and routines include:
\begin{enumerate}
\item After running the script, the individual plot functions are available
and the assignment of plots to the PDF file has been cancelled, so
you can re-generate any selected plots for console or RStudio display,
optionally with variable or time-segment modifications.
\item 'Review.R' can be incorporated into an Rnw document where comments
can be added to provide a record of problems identified or needing
further study, and this might be useful documentation to preserve
and distribute. This document is an example of that use.
\item It may be useful to make the plot functions in this routine available
as a package so they can be used easily without needing the full structure
of 'Review.R'. The plot functions reside in the directory PlotFunctions as individual R scripts.
\end{enumerate}

<<initialization,echo=FALSE,include=FALSE>>=

source ("chunks/initialization.R")

opts_chunk$set(fig.width=6, fig.height=5, fig.align="center", 
               digits=4, fig.show="asis")

@


\section{Running the program}

The script can be run in different ways. The simplest options are to 
run 'Review.R' from RStudio, 
run 'Rscript Review.R rf01' from a terminal window on tikal.eol.ucar.edu,
or source(\textquotedbl{}Review.R\textquotedbl{})
from an R console, including the console in RStudio. The program 
will use the name of the directory where it resides (e.g., WINTER)
as the name of the project, so it should be run from a directory
with the name of the project.

If command arguments are supplied, via 'Rscript Review.R rf01 -1 ...' then
these will over-ride the interactive commands that otherwise
ask for the flight and plot numbers desired. Run-time arguments are all strings:
\begin{enumerate}
\item{Flight:} e.g., rf01
\item{plots desired:} Project-default is "-1". Can also use "1,3,5" or "1:9,13"
\item{ShowPlots:} 3rd argument 0 suppresses saving plots; any other entry 
saves them. 1 produces HTML plots also; 2 does not but displays the
plots using \'evince\' when finished.
\item{Start time for the plots} in HHMMSS format. If >240000, use e.g. 250000 for 10000
\item{End time for plots} in HHMMSS format, as for Start time
\end{enumerate}
For example, 'Rscript Review.R rf03 17 0 220000 230000' displays plot 17 for
the listed times on an Xwindows screen. The script can be included in
a batch script using an entry like 'cd ~/RStudio/WINTER; Rscript Review.R rf01 -1'. 

When the program is run via 'source', it will interactively ask
for a flight name and a list of the plots desired. The flight
name should have the format ``rf09'' (without quote marks). The
plot description can be 0 (all plots), -1 (project default set), or
a series of plots in the format ``c(3,5,7)'' (without quotes).

<<configuration, include=FALSE, echo=FALSE>>=


source ("chunks/configuration.R")

<<get-data, include=TRUE, echo=FALSE>>=

source ("chunks/getData.R")

<<referenceFunctions, include=TRUE, echo=FALSE>>=

source ("chunks/referenceFunctions.R")

@



\section{Interpreting the plots}

These are short descriptions of the plot functions. In each case, functions 
generate the plots, often with multiple plots per function:
\begin{quotation}
plot 1: construct flight track with map

plot 2: construct one-per-hour track plots

plot 3: plot all temperatures, one plot

plot 4: plot differences, individual pairs of temperatures

plot 5: humidity

plot 6: ambient pressures

plot 7: dynamic pressure; also TAS and MACH

plot 8: total pressure (static and dynamic)

plot 9: wind

plot 10: Schuler oscillation

plot 11: attack, sideslip

Plot 12: IRU comparisons

plot 13: IRU continued, ACINS, VSPD

plot 14: (placeholder, not implemented)

plot 15: CN, FSSP, CDP, CONCP, UHSAS

plot 16: DBAR (mean diameters) and PLWC (liquid water content)

Plot 17: all-flight Skew-T

plot 18: plot skew-T for individual climbs and descents:

plot 19: potential-temperature plots

plot 20: CDP/SP100 size distributions

plot 21: Surface and sky radiometric temperatures

plot 22: UHSAS and PCASP size distributions

plot 30: Chemistry plots (CO2, CH4, H2O, CO)
\end{quotation}
It is also possible to generate a subset of the plots, and that will
also affect the plot numbering.
In the following description of the plots, proper figure numbers are
used for this example, but the numbering may change. The sequence,
however, should remain the same.

The plots in this memo are reduced in size compared to the PDF file
that is generated by running Review.R. When using this guide, it may
be useful to use the full-scale plots because some of the legends
and other features are hard to read at this reduced size. For each
plot, a few-paragraph description is provided. The intent of those
descriptions is to suggest how to interpret the plot as an indicator
of potential problems. Therefore, most of the descriptions give expected
tolerances for differences among sensors or other quantifiable departures
from expected behavior that should trigger further investigation of
the measurements. That is the intent of these plots: To provide quick
indications of problems so that they can be investigated further,
usually with other tools. Users should pay particular attention to
the tolerances denoted on many plots by dashed lines and to the titles
where mean differences between redundant measurements are listed.
Once a ``good'' set of plots is obtained for a project, that set
should be used as a reference for future flights because changes in
the patterns, even more than tests against specified tolerances, are
the best indicators of problems.

The examples presented here are from WINTER flight rf08,
a flight where most instruments performed fairly well. Some
exceptions are noted. 

<<fig-captions, include=TRUE>>=

source ("chunks/figCaptions.R")

@

<<reserve-for-Review.R, eval=FALSE>>=

source ("chunks/plotLoop.R")

@

\paragraph{Flight track:}

<<load-plot-functions>>=

### This section loads all the plot functions.
for (np in 1:nps) {
  if (file.exists (sprintf ("./PlotFunctions/RPlot%d.R", np))) {
    if (testPlot(np)) {
      eval(parse(text=sprintf("source(\"PlotFunctions/RPlot%d.R\")", np)))
#     eval(parse(text=sprintf("RPlot%d(DataV)", np)))
    }
  }
}

@

<<track-plot, fig.cap=c(RPlot1aCap, RPlot1bCap)>>=

if (testPlot(1)) {RPlot1(Data, Flight)}

<<plot-2>>=

if (testPlot(2)) {RPlot2 (Data)}

@

The first plot function generates two flight-track plots, Fig.~\ref{fig:track-plot1}
a plan-view and Fig.~\ref{fig:track-plot2} showing height-vs-time.
These provide general context that may be useful when looking at the
remaining plots, but they can be suppressed if desired because they
usually don't indicate problems with data quality. In some cases the
flight track becomes overlaid to such an extent that it is hard to
use, so for such cases it may be useful to enable nplot=2, which plots
separate flight tracks for each hour of flight. Normally this is disabled
as not particularly useful for quality-review of the data.

<<plot-3-temperature, fig.cap=RPlot3Cap>>=

# this code is for use in Review.R where the text of this memo is not included:
# for (np in 3:nps) {
# if (testPlot(np)) {eval(parse(text=sprintf("RPlot%d(DataV)", np)))}
# }
if (testPlot (3)) {RPlot3 (DataV)}
if (testPlot (4)) {RPlot4 (DataV)}

@


\paragraph{Air temperature:}

Figure \ref{fig:plot-3-temperature1} shows the time history of measured
air temperature from the various temperature sensors, 
and Fig. \ref{fig:plot-3-temperature2}
compares these sensors in pairs of measurements. After all corrections,
these should agree to within about 1$^{\circ}$C; claimed uncertainty
is about 0.3$^{\circ}$C. In particular, ATHR1 and ATHR2 should agree
to within about 0.3$^{\circ}$C.~ AT\_A, the temperature from the
aircraft avionics system, will often show larger scatter; this should
not be considered a problem unless it exceeds about 2 C. It appears
mostly because that measurement has slow response, either from filtering
or delays or both, and this usually accounts for the errors. It is
common to see two lines on the AT\_A-vs-ATHL2 plot for the same reason;
one is from measurements during climb and the other from those during
descent.

\paragraph{Humidity:}

Four plots are generated by function RPlot5 (). 
The first (Fig.~\ref{fig:humidity1})
shows the history of various measurements of dew point, including
those from sensors like the VCSEL for which dew
point must be calculated from the direct measurements.

<<humidity, fig.cap=RPlot5Cap>>=

if (testPlot (5)) {RPlot5 (DataV)}

@

Agreement among these measurements to within about 1$^{\circ}$C is
good. It is common to have problems during and after descent, like
those shown by the frequent spikes of dewpoint above temperature
and also apparent overshoot following climb also. The former occur
when the dew-point sensors overheat
in an effort to remove thick condensate that forms when the temperature
increases rapidly. ATX is also plotted on this history to provide
a reference: When the dew point temperature exceeds the temperature,
even by a few degrees, there is very likely a problem because this
almost never occurs in reality. For normal operation the mean
differences, listed at the top of the plot, should be within 
about 0.5$^{\circ}$.

The second plot (Fig.~\ref{fig:humidity2}) compares the measurements
to one selected as a reference, here DP\_VXL. 
Even though the scatterplot looks very scattered, there are also
many observations in reasonable agreement. Lags and overshoot problems
from the many climbs and descents during this flight cause the high
scatter. A plot like this shows unusually poor performance of the
dewpoint instruments, although the evidence from this set of plots
is that the VCSEL appears to be functioning well.
Errors patterns of horizontal or vertical lines in this plot
reflect, respectively, slow response by the dewpoint sensors and overshooting
on climb or descent. Although this plot looks poor, it is partly the result
of the flight pattern that was unusually variable in altitude.

Figure \ref{fig:humidity3} shows the cavity pressures in the dew-point
hygrometers. These are typically close to the ambient pressure (within
about 10 hPa) and slightly above PSFC, as for this case. They are
not necessarily the same because the sensors are oriented slightly
differently, but departure from the behavior shown may indicate that
the entrance holes are plugged or the pressure sensors are malfunctioning.
CAVP\_DPT is often 10 hPz higher than CAVP\_DPB. This plot also
shows the intensity of the laser beam in the VCSEL, with dashed red lines
indicating the normal range.

The final humidity plot, Fig.~\ref{fig:humidity4}, shows the history
of water vapor pressure, mixing ratio, and relative humidity. Excursions
above relative humidity of 100\% should be rare except in over-heating
events, but such events occur frequently during this flight. 
The several measurements of relative humidity plotted in the bottom
panel are not netCDF-file variables but are calculated from the
measurements of dew point. 
\vfill\eject

\paragraph{Ambient or static pressure: }
<<static-pressure, fig.cap=RPlot6Cap>>=
if (testPlot (6)) {RPlot6 (DataV)}
@
Figure \ref{fig:static-pressure} compares the redundant measurements
of ambient pressure, uncorrected (top panel) and corrected. The estimated
uncertainty in pressure measurements is about 0.3 hPa, so PSFDC and
PSFC (the redundant pressure measurements after correction) should
agree to within about this tolerance. In this example, the disagreement
is significantly outside this tolerance and therefore an indication of
a problem, although the mean difference is only about 0.8\,hPa.
A somewhat larger but still 1--2 hPa difference may be present for
PS\_A; the LAMS calibration consistently indicated a small error in
that measurement. 
The persistent difference of about this magnitude from the WINTER
project is an indication that there is some problem with the
pressure measurements or the pressure correction function being 
applied.

<<dynamic-pressure, fig.cap=RPlot7Cap>>=
if (testPlot (7)) {RPlot7 (DataV)}
@


\paragraph{Dynamic pressure:}

Measurements of dynamic pressure, similar to those from the ambient
pressure, are shown in Fig.~\ref{fig:dynamic-pressure1}. The uncertainty
in these measurements should be about 0.3 hPa, so the redundant sets
QCFC and QCFRC (bottom panel) should agree within about this tolerance.
As for PSFD and PSFRD, an offset is expected but that offset should
remain consistent. Any significant change should be an indicator of
a problem.

An additional plot, Fig.~\ref{fig:dynamic-pressure2}, shows two
measurements dependent on the dynamic-pressure measurements, TAS and
MACH. Only one TASF is available from the pair of measurements QCF
and QCFR, so these aren't compared here, but TASR and TAS\_A are redundant
measurements that, although of lower quality compared to TASF, should
remain without about 1\,m/s from TASF. \vfill\eject

<<total-pressure, fig.cap=RPlot8Cap>>=
if (testPlot (8)) {RPlot8 (DataV)}
@


\paragraph{Total pressure:}

Adding the measurements of dynamic and ambient pressure gives the
total pressure measured at the input of a pitot tube. Two independent
systems provide this measurement on the C-130, and the avionics system
provides a third measurement. These are compared in Fig.~\ref{fig:total-pressure}.
The difference between research-system measurements in the bottom
panel should be mostly less than 0.2 hPa and, on average, less than
0.1 hPa, as is true of the measurements used for this plot. \vfill\eject

<<wind, fig.cap=c(RPlot9Cap1, RPlot9Cap2)>>=
if (testPlot (9)) {RPlot9 (DataV)}
@


\paragraph{Wind:}

The measurements of horizontal and vertical wind are shown in Fig.~\ref{fig:wind1},
and also in terms of easterly and southerly components in Fig.~\ref{fig:wind2}.
Mean vertical wind averaged over the full flight should be close to
zero, usually with absolute magnitude less than about 0.2\,m/s;
this mean value is listed above the panel showing vertical wind. The horizontal
wind measurements can be used to check for reasonable continuity without
excessive noise, although when the wind speed is weak there may be
substantial noise in the WDC measurements. Wrap-around from 0 to 360
causes vertical lines in this plot that can be more frequent when
the wind direction is near 0 or 360. For this reason, the second plot,
showing easterly and southerly components, can be a better indicator
of continuity.%
\vfill\eject

<<schuler-oscillation, fig.cap=RPlot10Cap>>=
if (testPlot (10)) {RPlot10 (DataV)}
@


\paragraph{Schuler oscillation:}

The IRU measurements of ground speed will usually have some error
that varies in a Schuler oscillation with a period of about 84 min.
The magnitude of this oscillation is usually less than a few m/s,
and in the wind calculations this oscillation is removed by adjustment
to the GPS measurements, but excessive amplitude or unexpectedly noisy
measurements can indicate a problem worth investigating. Figure \ref{fig:schuler-oscillation}
shows the difference between ground-speed measurements from the IRU
and the GPS and will usually show an oscillation similar to that in
this example. The lowest panel in this plot shows the value of GGQUAL,
which will be 5 for OmniStar reception from the Novatel GPS receiver,
indicating highest-quality measurements. A value of 9 is best quality
without OmniStar reception.\vfill\eject


\paragraph{Angles of attack and sideslip:}

<<attack-sideslip, fig.cap=RPlot11Cap>>=
if (testPlot (11)) {RPlot11 (DataV)}
@
The sensitivity coefficients relating pressure differences on the
radome to angle of attack and sideslip have been described in a separate
memo (\href{https://drive.google.com/open?id=0B1kIUH45ca5AVFlKeHpWVG5Ed1U&authuser=0}{FRAPPEprocessing.pdf}).
That calibration used reference values of attack and sideslip (here
plotted as AOAREF and SSREF) that would be valid measures of the angles
of attack and sideslip if there were respectively zero vertical wind
and zero sideways wind gust.


Figure \ref{fig:attack-sideslip} shows a comparison of the measurements
to the reference values. If the calibration is valid, the blue and
red traces in the top plot and the blue and green traces in the bottom
plot should match in the mean, with occasional fluctuations caused
by real wind gusts. PITCH is also shown in the top plot because, in
the absence of both vertical wind and aircraft climb or descent, the
pitch would match the angle of attack. For the C-130, the usual angle
of attack is about $2\pm1^{\circ}$, so these limits are denoted on
the top panel. Notice the gradual decrease in angle of attack during
the course of the flight; this is normal behavior as the weight of
the aircraft decreases. Plots like these are good indications that
the radome calibration is valid. This is useful to monitor because
there have been some unexplained changes in C-130 radome behavior,
perhaps from changes in mounting alignment or from flow interference
from small accretions of dirt near the radome ports.


\paragraph{Aircraft attitude angles: pitch, roll, heading}

<<iru-comparisons, fig.cap=RPlot12Cap>>=
if (testPlot (12)) {RPlot12 (DataV)}
@

The research IRUs provide redundant measurements of the attitude angles,
so comparing them tests if they remain consistent. They should agree
to within about 0.05$^{\circ}$ except for possible errors in alignment
when the units are installed in the aircraft.

Figure \ref{fig:iru-comparisons} shows the measurements from the
two inertial systems and also a magnified (red) plot of the differences
between the two units (IRS1 value minus IRS2 value). Dashed red lines
show the expected tolerances for these magnified differences. For
pitch, typical values are about 2$^{\circ}$ as expected and the offset
is about 0.03$^{\circ}$ between the two systems. Because this is
so steady for this flight, it is probably an indication of a real
difference in alignment, which should be considered if the primary
unit used for wind calculations is changed. For roll, the mean difference
is near zero. No average value is shown for the heading offset because
the average is dominated by occasional large positive excursions,
producing a large positive mean even though it appears that the baseline
is about -0.25$^{\circ}$as indicated by the dashed green line. This
offset likely arises from misalignment to this extent on installation.
When monitoring these measurements, consistency of these offsets is
the primary criterion to use; the magnitude of the heading offset,
for example, is not a problem unless it become necessary to use the
alternate IRU in wind measurements.\vfill\eject


\paragraph{Vertical acceleration, vertical velocity of the aircraft, and aircraft
altitude}

<<iru-acins, fig.cap=RPlot13Cap>>=
if (testPlot (13)) {RPlot13 (DataV)}
@

Figure \ref{fig:iru-acins} provides additional information on the
performance of the INS and GPS systems. The top panel shows a comparison
of the measurements of vertical acceleration; these should match to
strict tolerance because the acceleration is integrated twice to get
the altitude. The difference, shown here as -0.002, should be less
than about 0.01 in magnitude for normal good operation of the inertial
units. This does not have to be exactly zero because the data used
are qualified to have TASX > 60, so some brief periods near the start
and end of flights can be omitted. The middle panel shows the vertical
speed of the aircraft as measured by three independent systems. All
are in good agreement, and the flight-mean values are <0.001 and -0.006\,m/s
respectively for the inertial and GPS-Novatel units. The mean velocity
should be very close to zero for a flight that takes off and lands
at the same airport. The bottom panel will normally show the four
traces from independent systems overlapping so much as to be indistinguishable.
In this case, there are occasional spikes in the altitude from the
Novatel GPS that indicate a problem needing investigation.\vfill\eject


\paragraph{UHSAS}

<<uhsas>>=
#if (testPlot (14)) {RPlot14 (DataV)}
@

The UHSAS was not operated on FRAPPE so this section will need to
be provided once measurements from WINTER are available.


\paragraph{CN, PCASP, FSSP, CDP, and UHSAS concentrations}

<<cn-fssp, fig.cap=c(RPlot15aCap, RPlot15bCap), fig.width=6.5, fig.height=7>>=

if (testPlot (15)) {RPlot15 (DataV)}

@

The plots in this section show measurements from particle and hydrometeor
distrometers on the C-130. The top panel of the first figure, Fig.~\ref{fig:cn-fssp1},
shows CN counts and the CN concentration determined from them, as
well as the concentrations from the PCASP and UHSAS. The bottom panel shows concentrations
from the CDP, FSSP, and 2DC. The apparent floor on the plot of
CDP concentration arises because that is the threshold for a single
droplet counted in the 1-s interval used for these measurements. Zero
values are reset to missing for these log plots.
this case, there is reasonable agreement between the CDP and FSSP concentrations.
These are all reasonable-looking measurements. One useful
check is to look for correlation among these measurements, as is clearly
present here for the top-panel aerosol measurements. The 2DC concentration
should remain zero in cases of flight outside cloud, as it does except
for a few brief bursts; a steady concentration
above zero in clear air may indicate a problem with the uniform illumination
of diodes or a bad diode in the instrument.

Plot routine RPlot15.R also generates plots of some measurements of
flows and laser voltages, shown in Fig.~\ref{fig:cn-fssp2}. 
\vfill\eject


\paragraph{Mean diameters and liquid water content of hydrometeors}

<<dbar-plwc, fig.cap=RPlot16Cap>>=
if (testPlot (16)) {RPlot16 (DataV)}
@

Measurements of mean diameter and liquid water content at low levels
can be quite noisy and therefore hard to interpret, so the plots in
this section have been smoothed over running periods of 61 s using
cubic Savitzky-Golay polynomials. That led to much smoother plots
that are easier to interpret, as shown in Fig.~\ref{fig:dbar-plwc1},
but at the expense of losing fine resolution in cases of short passage
through clouds. For that reason, this plot and the others in this
section are likely only useful for data-quality review, not for analysis
conclusions.

The mean diameters shown in the top panel of Fig.~\ref{fig:dbar-plwc1}
show that the CDP and FSSP are in good agreement during the cloud
pass beginning at about 15:10:00. Both also remain with mean diameters
in the smallest channels for flight outside cloud, as is normal.
The mean diameter from the PCASP measures larger sizes during the
cloud pass than the UHSAS, perhaps as a result of shattering, and the
2DC shows that there are some hydrometeors larger than cloud droplets in
the cloudy region. 

The same smoothing is applied to the liquid water content measurements
shown in the top panel of Fig.~\ref{fig:dbar-plwc2}. In the plotted
case, there measurements of liquid water content from the CDP, FSSP, and
King probes are all in good agreement during the cloud pass and all
suitably near zero outside cloud. The center panel shows that the King
probe is running with power slightly higher than usual, but this should
still give good performance.
Normally this power
should remain steady during the project unless probe elements are
changed. The guidelines on this plot can help detect departures from
normal operation. Finally, the bottom panel shows the liquid water
content deduced from the 2DC probe. Here it is appropriately quiet
outside cloud and provides a reasonable value for the cloud pass.

For monitoring purposes, Fig.~\ref{fig:dbar-plwc3} shows some measurements
characterizing the operation of the FSSP. The instrument rejects droplets
for two reasons, either because it estimates they are outside the
depth of field or because their transit time is shorter than the average
and can indicate passage through the edges of the beam. The displayed
results are smoothed to reduce noise, especially prior to the cloud
encounter, and provide suitably steady measurements in cloud with
DOF acceptance fraction of about 20--30\% and time-of-flight acceptance
fraction of about 65\%. These are reasonable values. The bottom
panel shows the FSSP laser voltage with expected limits.
\vfill\eject


\paragraph{Plots on a thermodynamic (skew-T) diagram}

<<skewt-all, fig.cap=RPlot17Cap, fig.height=5, warning=FALSE>>=

source ("~/RStudio/Ranadu/R/SkewT.R")
if (testPlot (17)) {RPlot17 (DataV)}
@

Skew-T diagrams can indicate problems if they show regions where the
temperature decreases with altitude faster than expected for parcel
ascent, and they can also indicate layers of strong stability where
boundary-layer pollution may be trapped. They can also indicate the
potential for the development of clouds and the potential for severe
weather. A skew-T plot is included here (Fig.~\ref{fig:skewt-all}
for information and context, but as long as the appearance remembles
this plot it will probably not add to the quality-control information.
There is also a section of this program, suppressed in the project
configuration, that searches for climbs and descents and constructs
separate plots for them. Include 18 in the sequence named 'nplots'
to see these individual plots. They are suppressed in this memo. \vfill\eject

<<skewt-climb-descent, fig.cap=RPlot18Cap, fig.height=7, fig.width=6>>=
if (testPlot (18)) {RPlot18 (DataV)}
@


\paragraph{Potential temperature profiles}

<<potential-temperatures, fig.cap=RPlot19Cap, fig.height=5>>=
if (testPlot (19)) {RPlot19 (DataV)}
@

Figure \ref{fig:potential-temperatures1} shows the history of measurements
of various potential temperatures during the flight, and Fig.~\ref{fig:potential-temperatures2}
shows the same measurements in vertical profile. The latter can be
useful because it is expected that potential temperature (THETA or
THETAV) will normally decrease or remain steady as the altitude increases,
and uniform regions indicate possible well-mixed regions such as the
Earth's boundary layer, often capped by modest stability reflected
in increasing THETA. These profiles often will show multiple lines
because all individual measurements are plotted in connected lines,
so for example there may be one plot for ascent and one for descent.
Much more can be deduced by using profiles like these, but for the
purposes of data review the best test is to expect plots resembling
these and investigate departures. 
For this flight, the sensor assigned for calculation of derived
variables was DPB so many of the errors associated with lags and
overshooting in this device will influence derived variables also.
\vfill\eject


\paragraph{Hydrometeor size distributions}

<<droplet-size-distributions, fig.cap=RPlot20Cap, fig.height=5>>=
if (testPlot (20)) {RPlot20 (DataV)}
@

Size distributions measured by the CDP and SPP100 (FSSP) are shown
in the next set of plots beginning with Fig.~\ref{fig:droplet-size-distributions1}.
Individual plots show measurements made over 1-s, as labeled at the
top of the plots, and plots are only generated when at least one channel
in the CDP measures a concentration of more than 1 cm$^{-3}$. Once
four pages of plots are generated, the plotting is suppressed, so
this only provides an initial limited sample. \vfill\eject

\paragraph{Radiometric temperatures}

<<radiometers, fig.cap=RPlot21Cap>>=

if (testPlot (21)) {RPlot21 (DataV)}

@

Measurements from two down-looking radiometers are compared in the
top panel of Fig.~\ref{fig:radiometers}, where the difference should
remain between the limits shown by dashed lines. The bottom panel shows the
measurements from the upward-looking radiometer, which should provide the
temperature from the sky or, in the case of dense cloud, the cloud-base
temperature.

\paragraph{Aerosol size distributions}

<<aerosol-spec, fig.cap=RPlot22Cap>>=

STsave <- StartTime
StartTime <- 110000
if (testPlot (22)) {RPlot22 (DataV)}
StartTime <- STsave

@

Aerosol size distributions from the UHSAS and PCASP are shown starting with
Fig.~\ref{fig:aerosol-spec1}. Like the distributions from the CDP/FSSP, these are only
plotted when the concentrations exceeds a threshold, in this case for
some UHSAS bin exceeding 50 or some PCASP bin exceeding 1. Plotting stops
after four pages of output.

In this case, the UHSAS did not start the flight operating properly but
began to function properly later in the flight. Usually these plots shown
only a few seconds near the start of the flight, but in this case the
plots were suppressed until after 11:00 to be able to show some examples
where the size distributions from the UHSAS and PCASP were similar and
both appeared to be working properly.

\paragraph{Chemistry}


Measured trace species include CO$_2$, CH$_4$, CO and H$_2$O. Plots beginning
with Fig.~\ref{fig:chemistry1} characterize these measurements. The first two plots
show CO$_2$ and CH$_4$ before and after corrections for the presence of water vapor, and Fig.~\ref{fig:chemistry5} shows the dependence of those corrections
on water vapor as measured by the Picarro 2311. The measurement of water vapor
from the Picarro is compared to that from the VCSEL in Figs.~\ref{fig:chemistry3} and \ref{fig:chemistry4}, and Figs.~\ref{fig:chemistry6} and \ref{fig:chemistry7} show the uncorrected measurements of CO and some related housekeeping measurements.

<<chemistry, fig.cap=c(RPlot30aCap, RPlot30bCap, RPlot30cCap,  RPlot30dCap,  RPlot30eCap,  RPlot30fCap,  RPlot30gCap)>>=

if (testPlot (30)) {RPlot30 (DataV)}

@

<<speed-run-search, eval=FALSE>>=

SpeedRunSearch (DataV)
if (SavePlotsToFiles) {
  dev.off()
  system (sprintf ("evince %s", plotfile))
}

@
\vfill\eject

\section{How to add new plots}

Here is the procedure for adding a plot to this routine:
\begin{enumerate}
\item Copy this code and save it in the PlotFunctions directory with an appropriate value of N, both in the file name (which should be 'RPlotN.R', and in the function name. At present, numbers 14 and 23--29 are unused.\\
<<model-addition, echo=TRUE, eval=FALSE>>=
### This is a model for adding a function:
RPlotN <- function(data) {
  # next just resets geometry, in case previous plot used multiple panes
  op <- par (mfrow=c(1,1), mar=c(5,5,2,2)+0.1)
  ## simplest plot: variables "Var1" and "Var2" vs time
  plotWAC (data[, c("Time", "Var1", "Var2"), ylab="Var"]  
}
@
\item Make sure that the needed variables are in the text file ``VarList''. If not,
add them to that file following the format in use.
Any variables must be in the netCDF file or else this program will
crash; it is not protected against this error.
\item Then, as long as the number is less than 30, the plot loop will
run the new function in order and include the new plot in the plot file.
\item You can then make additional modifications to the function as you
see the results and want to change them. Use the functions RPlot{[}1:20{]}
in Review.R for ideas of ways to tailor the plots. Also, there are
some functions available that you may find useful:

\begin{enumerate}
\item hline (X) will draw a black dashed horizontal line on the plot at
ordinate value X.
\item SmoothInterp (X) will return a smoothed version of X (which might
be a variable like data\$TASX) as referenced in your routine). Usage:
Xsmoothed <- SmoothInterp (X).
\end{enumerate}
\item Finally, please write a description of how to interpret the new plot
and what to look for when reviewing data. Give that to me for incorporation
into future versions of this memo.
\end{enumerate}
\begin{center}
\textsf{\textcolor{blue}{-- End of Memo --}}
\par\end{center}

Reproducibility:

\begin{tabular}{ll}
\textsf{\textsc{\textcolor{blue}{Project:}}} & Review\tabularnewline
\textsf{\textsc{\textcolor{blue}{Programs:}}} & \Sexpr{thisFileName}.Rnw, \Sexpr{thisFileName}.R and included functions\tabularnewline
\textsf{\textsc{\textcolor{blue}{Original Data:}}} & /scr/raf\_data/\Sexpr{Project}/\Sexpr{Project}\Sexpr{Flight}.nc -- field version \tabularnewline
\textsf{\textsc{\textcolor{blue}{Git:}}} & https://github.com/WilliamCooper/WINTER.git (as Review.zip)\tabularnewline
\end{tabular}
\end{document}
